---
layout: post
title:  "Data science@LHC"
date:   2015-11-12
author: Richard Wilkinson
authorurl: http://r-wilkinson.staff.shef.ac.uk

categories: jekyll update blog
---

**

[http://indico.cern.ch/event/395374/](Meeting on data science)

[https://cds.cern.ch/record/2067048](Talk link)


I was slightly sceptical about the value of CERN before my visit, probably due to the BBC's insistence on discussing it with unnecessary mystical reverence at great length and on a regular basis, provoking professional jealousy. But the tour today was quite mind blowing, just for the scale of the operation, the challenges involved, and that an operation this large run by academics could be successful. Luckily my visit coincided with a short stop in the LHC, which allowed us to go down to the collider.
The most interesting talk at the workshop was by Demis Hassabis, CEO of Google DeepMind, and had nothing to do with HEP. He showed how a single deep neural net can be trained to play 100s of computer games from the 80s, when given no information other than the pixels in each frame, and a score. No one in the Q&A asked about Skynet, despite, I discovered later, nearly everyone thinking exactly the same thing.
Eilam Gross, the convenor of the experiment that discovered the Higgs, suggested (I've probably mis-interpretted to hear what I wanted to hear) that the Higgs discovered should be chalked up to statistics as much as physics. The huge quantity of data they needed to process, several tera bytes a second, to discover an event that happened ~40 times in 3 years of running the LHC, is incredible. In the past two years I've been to neuroscience, climate, industrial maths, statistics and machine learning conferences, and the ML conferences feel by far the most energetic and exciting, but its possible that this is because everyone is waiting for google/fb to make them rich.
